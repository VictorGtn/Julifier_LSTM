{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scrapping the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBJCNpwbb8sP",
        "outputId": "63db6cc2-7740-48d9-a4b0-62409fd3cca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lyricsgenius in c:\\users\\victo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in c:\\users\\victo\\appdata\\roaming\\python\\python38\\site-packages (from lyricsgenius) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in c:\\users\\victo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lyricsgenius) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\victo\\appdata\\roaming\\python\\python38\\site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\victo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victo\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.20.0->lyricsgenius) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.20.0->lyricsgenius) (2020.6.20)\n"
          ]
        }
      ],
      "source": [
        "!pip install lyricsgenius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nS_MOVMQWlfU"
      },
      "outputs": [],
      "source": [
        "from lyricsgenius import Genius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "EV_JLMiAWmTH",
        "outputId": "6d1939ea-ad28-42c9-cfb0-3b39a20d7934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for songs by jul...\n",
            "\n",
            "Changing artist name to 'JuL'\n",
            "Song 1: \"13*\"\n",
            "Song 2: \"135 City\"\n",
            "Song 3: \"1er dans la bataille\"\n",
            "Song 4: \"1 fois mais pas 2\"\n",
            "\"2 visages\" is not valid. Skipping.\n",
            "Song 5: \"4 heures du mat’\"\n",
            "Song 6: \"4 Juin 2022\"\n",
            "Song 7: \"500 Chevaux\"\n",
            "Song 8: \"6.35\"\n",
            "Song 9: \"Abandonner*\"\n",
            "Song 10: \"À bout de nerf\"\n",
            "Song 11: \"A.C.C.C\"\n",
            "Song 12: \"À coup de crick\"\n",
            "Song 13: \"À coup de taser\"\n",
            "Song 14: \"À croire que\"\n",
            "Song 15: \"Affaire de famille*\"\n",
            "\"À FORCE DE VIVRE\" is not valid. Skipping.\n",
            "Song 16: \"Africa Twin\"\n",
            "Song 17: \"Aghju Capitu\"\n",
            "Song 18: \"Agis ou ferme tgl\"\n",
            "Song 19: \"Agression*\"\n",
            "Song 20: \"Ah c’est comme ça !\"\n",
            "Song 21: \"Ailleurs\"\n",
            "Song 22: \"Akha*\"\n",
            "Song 23: \"À la cité\"\n",
            "Song 24: \"À la fou\"\n",
            "Song 25: \"À la russe\"\n",
            "Song 26: \"À la vida à la muerte\"\n",
            "Song 27: \"À la vue\"\n",
            "Song 28: \"Alcantara\"\n",
            "Song 29: \"Alcoolisé\"\n",
            "Song 30: \"À l’impro\"\n",
            "Song 31: \"All Eyez on Me\"\n",
            "Song 32: \"Allez le sang\"\n",
            "Song 33: \"Alors la zone\"\n",
            "Song 34: \"Amigo\"\n",
            "Song 35: \"Amis ennemis\"\n",
            "Song 36: \"Amnésia\"\n",
            "Song 37: \"Amore\"\n",
            "Song 38: \"Anti-BDH\"\n",
            "Song 39: \"Aqua dans la Mercedes\"\n",
            "Song 40: \"Arrête de faire ta folle*\"\n",
            "Song 41: \"Arrête de parler\"\n",
            "Song 42: \"Asalto\"\n",
            "Song 43: \"Askip\"\n",
            "Song 44: \"Assassinat\"\n",
            "Song 45: \"Au bord de la mer\"\n",
            "Song 46: \"Au-dessus de l’Atlas\"\n",
            "Song 47: \"Audi volée\"\n",
            "Song 48: \"Aujourd’hui\"\n",
            "Song 49: \"Au péage\"\n",
            "Song 50: \"Au pire\"\n",
            "Song 51: \"Au quartier\"\n",
            "Song 52: \"Au quartier (Version album)\"\n",
            "Song 53: \"Avant GTR\"\n",
            "Song 54: \"Avant la douane\"\n",
            "Song 55: \"Avec José\"\n",
            "Song 56: \"Avec la chapka\"\n",
            "Song 57: \"Avec mes gars\"\n",
            "Song 58: \"Baby*\"\n",
            "Song 59: \"Bagarre\"\n",
            "Song 60: \"Baïla\"\n",
            "Song 61: \"Bandit\"\n",
            "Song 62: \"Battistu\"\n",
            "Song 63: \"BDG\"\n",
            "Song 64: \"Bé\"\n",
            "Song 65: \"Beely\"\n",
            "Song 66: \"Beuh à la framboise\"\n",
            "Song 67: \"Beuh à la noix de coco\"\n",
            "Song 68: \"Beuh magique\"\n",
            "Song 69: \"Bientôt je me taille\"\n",
            "Song 70: \"Bobo au Corazon\"\n",
            "Song 71: \"Bonne année\"\n",
            "Song 72: \"Booska Crizeotiek\"\n",
            "Song 73: \"Booska dans la nuque Part. 1\"\n",
            "Song 74: \"Booska dans la nuque Part. 2\"\n",
            "Song 75: \"Booska dans la nuque Part. 3\"\n",
            "Song 76: \"Booska Sangoku\"\n",
            "Song 77: \"Borussia\"\n",
            "Song 78: \"Bouge-moi de là\"\n",
            "Song 79: \"Boulevard des problèmes\"\n",
            "Song 80: \"Bravo\"\n",
            "Song 81: \"Briganté\"\n",
            "Song 82: \"Brouncha\"\n",
            "Song 83: \"Bruce Lee\"\n",
            "Song 84: \"Buakaw\"\n",
            "Song 85: \"Burberry\"\n",
            "Song 86: \"Bwo\"\n",
            "Song 87: \"Ça...\"\n",
            "Song 88: \"Ça a tiré\"\n",
            "Song 89: \"Cagoulé\"\n",
            "Song 90: \"Ça m’a mis dedans\"\n",
            "Song 91: \"Ça mange la barre\"\n",
            "Song 92: \"Ça me dégoûte\"\n",
            "Song 93: \"Ça me guintch\"\n",
            "Song 94: \"Camouflage\"\n",
            "Song 95: \"Ça ne change pas\"\n",
            "Song 96: \"Canette dans les mains\"\n",
            "Song 97: \"Ça rêve\"\n",
            "Song 98: \"Carnalito\"\n",
            "Song 99: \"Carré d’as\"\n",
            "Song 100: \"Cartel de platine\"\n",
            "Song 101: \"Ça sent bon\"\n",
            "Song 102: \"#CASSAGEDENUQUESPARTIE1\"\n",
            "Song 103: \"Cassage de nuques, Pt. 1\"\n",
            "Song 104: \"Cassage de nuques, Pt. 2\"\n",
            "Song 105: \"Cassage de nuques, Pt. 3\"\n",
            "Song 106: \"Cassage de nuques, Pt. 4\"\n",
            "Song 107: \"Ça tombe pas du ciel\"\n",
            "Song 108: \"Ça tourne dans ma tête\"\n",
            "Song 109: \"Ça va chérie ça va\"\n",
            "Song 110: \"Ça va péter\"\n",
            "Song 111: \"Ça veut ton cash\"\n",
            "Song 112: \"Ça vient de là\"\n",
            "Song 113: \"Ce que je vois\"\n",
            "Song 114: \"Ce soir\"\n",
            "Song 115: \"C’est ça\"\n",
            "Song 116: \"C’est ça la vie\"\n",
            "Song 117: \"C’est ça que je te reproche\"\n",
            "Song 118: \"C’est chaud\"\n",
            "\"C’est criminel\" is not valid. Skipping.\n",
            "Song 119: \"Ces temps-ci\"\n",
            "Song 120: \"C’est la cité\"\n",
            "Song 121: \"C’est la crise\"\n",
            "Song 122: \"C’est la seule\"\n",
            "Song 123: \"C’est le son de la gratte\"\n",
            "Song 124: \"C’est l’heure\"\n",
            "Song 125: \"C’est pas beau\"\n",
            "Song 126: \"C’est pas des LOL\"\n",
            "Song 127: \"C’est pas facile\"\n",
            "Song 128: \"C’est pas facile (La route est longue)\"\n",
            "Song 129: \"C’est pas grave*\"\n",
            "Song 130: \"C’est pas la mairie\"\n",
            "Song 131: \"C’est pas la peine*\"\n",
            "Song 132: \"C’est pas ma faute\"\n",
            "Song 133: \"C’est quand qu’il s’éteint ?\"\n",
            "Song 134: \"C’est réel\"\n",
            "Song 135: \"C’est rien\"\n",
            "Song 136: \"C’est trop\"\n",
            "Song 137: \"C’est un bonbon\"\n",
            "Song 138: \"Cette fois\"\n",
            "Song 139: \"Chagriné\"\n",
            "Song 140: \"Chapeau de paille\"\n",
            "Song 141: \"Charbon\"\n",
            "Song 142: \"Chargé\"\n",
            "Song 143: \"Chemin de morgiou\"\n",
            "Song 144: \"Chez moi\"\n",
            "Song 145: \"Chiron\"\n",
            "Song 146: \"Chocolata\"\n",
            "Song 147: \"Chut écoute*\"\n",
            "Song 148: \"Ciro\"\n",
            "Song 149: \"Coco\"\n",
            "Song 150: \"Cœur blanc\"\n",
            "Song 151: \"Cœur blessé\"\n",
            "Song 152: \"Cœur démoli\"\n",
            "Song 153: \"Cogno\"\n",
            "Song 154: \"Collé au mic\"\n",
            "Song 155: \"Come vai\"\n",
            "Song 156: \"Comme à l’époque\"\n",
            "Song 157: \"Comme au bon vieux temps\"\n",
            "Song 158: \"Comme d’hab\"\n",
            "Song 159: \"Comme les gens d’ici\"\n",
            "Song 160: \"Comment ça va se finir*\"\n",
            "Song 161: \"Comment te dire\"\n",
            "Song 162: \"Comme une machine\"\n",
            "Song 163: \"Comme un fou\"\n",
            "Song 164: \"Comme un voyou\"\n",
            "Song 165: \"¿Cómo Te Llamas?\"\n",
            "Song 166: \"Comprendo Señorita\"\n",
            "Song 167: \"Confinement\"\n",
            "\"Contaminer\" is not valid. Skipping.\n",
            "Song 168: \"Coucou\"\n",
            "Song 169: \"Coup de foudre\"\n",
            "Song 170: \"Coup de genoux\"\n",
            "Song 171: \"Couplet*\"\n",
            "Song 172: \"Courtois\"\n",
            "Song 173: \"Courtoisie\"\n",
            "Song 174: \"Cousine\"\n",
            "Song 175: \"Crapuleux\"\n",
            "Song 176: \"Cremosso\"\n",
            "Song 177: \"Crocodile\"\n",
            "Song 178: \"Dans la cour\"\n",
            "Song 179: \"Dans la légende\"\n",
            "Song 180: \"Dans la loge\"\n",
            "Song 181: \"Dans l’appart\"\n",
            "Song 182: \"Dans la voiture à Batman\"\n",
            "Song 183: \"Dans la zon\"\n",
            "Song 184: \"Dans le 13\"\n",
            "Song 185: \"Dans le club\"\n",
            "Song 186: \"Dans le futur\"\n",
            "Song 187: \"Dans le gamos\"\n",
            "Song 188: \"Dans l’game\"\n",
            "Song 189: \"Dans ma cité\"\n",
            "Song 190: \"Dans ma mama\"\n",
            "Song 191: \"Dans ma paranoïa\"\n",
            "Song 192: \"Dans mon cœur\"\n",
            "Song 193: \"Dans mon dél\"\n",
            "\"Dans mon secteur\" is not valid. Skipping.\n",
            "Song 194: \"Dans sa bulle\"\n",
            "Song 195: \"Dans tes yeux\"\n",
            "Song 196: \"Dans un autre monde\"\n",
            "Song 197: \"Dans une autre planète\"\n",
            "Song 198: \"Davai davai\"\n",
            "Song 199: \"Délicieuse\"\n",
            "Song 200: \"De retour\"\n",
            "Song 201: \"Désolé\"\n",
            "Song 202: \"Dingue dingue*\"\n",
            "Song 203: \"Dors on te piétine\"\n",
            "Song 204: \"Dors petit dors\"\n",
            "Song 205: \"D’où je viens\"\n",
            "Song 206: \"Dounia (Remix)*\"\n",
            "Song 207: \"DP sur le maillot\"\n",
            "Song 208: \"Drogue love\"\n",
            "Song 209: \"Droit au but\"\n",
            "Song 210: \"Drôle de dame\"\n",
            "Song 211: \"Drôle de vie\"\n",
            "Song 212: \"Du jour au lendemain\"\n",
            "\"Du love à la rage\" is not valid. Skipping.\n",
            "Song 213: \"Du Nord au Sud*\"\n",
            "Song 214: \"Dur-Dur\"\n",
            "Song 215: \"Écoute ça\"\n",
            "Song 216: \"Eh ça va Guy\"\n",
            "Song 217: \"Eh ouais fils\"\n",
            "Song 218: \"Électrique\"\n",
            "Song 219: \"Elle\"\n",
            "Song 220: \"Elle et l’autre\"\n",
            "Song 221: \"Elle (Remix L.E.C.K)*\"\n",
            "Song 222: \"Elle te balade\"\n",
            "Song 223: \"Elle veut\"\n",
            "Song 224: \"Emmenez-moi\"\n",
            "Song 225: \"Émotions\"\n",
            "Song 226: \"En attendant\"\n",
            "Song 227: \"En cas de...\"\n",
            "Song 228: \"En chair et en or\"\n",
            "Song 229: \"Encore des paroles\"\n",
            "Song 230: \"En crabe\"\n",
            "Song 231: \"En douceur\"\n",
            "Song 232: \"En fumette*\"\n",
            "Song 233: \"En Live de Periscope\"\n",
            "Song 234: \"En place\"\n",
            "Song 235: \"En quarantaine\"\n",
            "Song 236: \"En revenant d’Alicante\"\n",
            "Song 237: \"Entraînement\"\n",
            "Song 238: \"En two two bé\"\n",
            "Song 239: \"En Y\"\n",
            "Song 240: \"Équipe énervée\"\n",
            "\"Essaie de nous suivre\" is not valid. Skipping.\n",
            "Song 241: \"E.T.\"\n",
            "Song 242: \"État d’âme\"\n",
            "Song 243: \"Et je deviens fou\"\n",
            "Song 244: \"Et ouais\"\n",
            "Song 245: \"Europa\"\n",
            "Song 246: \"Évasion\"\n",
            "Song 247: \"[EXCLU] Freestyle inédit de Jul dans Planète Rap #Emotions (Part 2)\"\n",
            "Song 248: \"Facilement\"\n",
            "Song 249: \"Fair*\"\n",
            "Song 250: \"Fais-moi la passe\"\n",
            "\n",
            "Reached user-specified song limit (250).\n",
            "Done. Found 250 songs.\n",
            "[Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...), Song(id, artist, ...)]\n"
          ]
        }
      ],
      "source": [
        "genius = Genius('A4acQipb4pwRRNdOq06t4A_CYoYBDJR3rCONvPcN84bEwvia3jS8sVq7LnccAfYc',remove_section_headers = True,)\n",
        "jul = genius.search_artist(\"jul\", sort=\"title\",get_full_info=True,max_songs=250)\n",
        "print(jul.songs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Processing of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "buBzSjz1WnVZ"
      },
      "outputs": [],
      "source": [
        "n=len(jul.songs)\n",
        "data = []\n",
        "for i in range(n):\n",
        "    data.append(jul.songs[i].lyrics)\n",
        "data = data[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "XtYS6F0wbgr6",
        "outputId": "c006f402-8be4-45c1-b0db-a37a658ec964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 Contributors1 fois mais pas 2 Lyrics\n",
            "\n",
            "Y'avait pas beaucoup de monde quand j'me noyais\n",
            "Mais t'façon rien à foutre des autres\n",
            "J'ai dit à maman : \"Tu paieras plus l'loyer\"\n",
            "Tes fils, c'est devenu des hommes\n",
            "Tu me l'as fait à moi ? 3enenni\n",
            "Fais pas le con, fais pas le fou, fais demi\n",
            "Elle sent le Dior, elle veut le sac, L.V\n",
            "J'ai pas le temps si j'vends chaque ennemi\n",
            "J'ai passe à bloc en bolide, ouais, ouais\n",
            "Elle est bonne comme ma weed, ouais, ouais\n",
            "Ellе m'a souri, j'fais demi, ouais, ouais\n",
            "Je m'arrête, j'la validе, ouais, ouais\n",
            "\n",
            "On se plaît, on se voit\n",
            "Toi et moi on va boire un verra, j'regarde pas l'heure\n",
            "Tu m'auras, tu m'auras\n",
            "Tu m'auras une fois mais pas deux, j'fais plus l'erreur\n",
            "\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "You might also like\n",
            "Ouais ce soir, ça s'est mis frais (Ah-ah, ah-ah)\n",
            "T'es pas rentré, qu'est-ce t'as fait ? (Ah-ah, ah-ah)\n",
            "Ouais ce son, c'est pour les vrais (Ah-ah, ah-ah)\n",
            "Ceux et celles qu'ont galéré (Ah-ah, ah-ah)\n",
            "\n",
            "J'piste à droite, à gauche\n",
            "J'peux pas fumer tranquille, j'peux pas m'poser au calme\n",
            "Fais pas ta belle, t'es moche\n",
            "J'suis dans le big love, normal, j'te recale\n",
            "Donne-moi ton numéro, per favore\n",
            "J'te rappelle ce soir ma jolie\n",
            "J'te récup' en moto, on trace\n",
            "J'ai d'la ppe-f', faut qu'on esquive la police\n",
            "C'était ton fils au mic'\n",
            "Faudrait qu'ils arrêtent d'mentir sur leur life\n",
            "Mon cœur, t'es mon rayon de soleil\n",
            "J'peux pas voir ailleurs, toi t'es ma wife\n",
            "\n",
            "On se plaît, on se voit\n",
            "Toi et moi on va boire un verra, j'regarde pas l'heure\n",
            "Tu m'auras, tu m'auras\n",
            "Tu m'auras une fois mais pas deux, j'fais plus l'erreur\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "\n",
            "Ouais ce soir, ça s'est mis frais (Ah-ah, ah-ah)\n",
            "T'es pas rentré, qu'est-ce t'as fait ? (Ah-ah, ah-ah)\n",
            "Ouais ce son, c'est pour les vrais (Ah-ah, ah-ah)\n",
            "Ceux et celles qu'ont galéré (Ah-ah, ah-ah)\n",
            "\n",
            "On se plaît, on se voit\n",
            "Toi et moi on va boire un verra, j'regarde pas l'heure\n",
            "Tu m'auras, tu m'auras\n",
            "Tu m'auras une fois mais pas deux, j'fais plus l'erreur\n",
            "\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "\n",
            "Ouais ce soir, ça s'est mis frais (Ah-ah, ah-ah)\n",
            "T'es pas rentré, qu'est-ce t'as fait ? (Ah-ah, ah-ah)\n",
            "Ouais ce son, c'est pour les vrais (Ah-ah, ah-ah)\n",
            "Ceux et celles qu'ont galéré (Ah-ah, ah-ah)\n",
            "Habibi-bibi\n",
            "Habibi-bibi-bibi\n",
            "Habibi-bibi\n",
            "HabibiEmbed\n"
          ]
        }
      ],
      "source": [
        "print(data[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get rid of the first line of the data, which is the header.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "hGzcLEJlWp3Y"
      },
      "outputs": [],
      "source": [
        "cleaned_data = []\n",
        "for i in data:\n",
        "    intro_index = i.find(\"\\n\")\n",
        "    cleaned_data.append(i[intro_index+1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ANi_HEnvbgr-",
        "outputId": "0d457cf4-5cd2-4ad8-fb0c-e8363b9845ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1.3.5\n",
            "1.3.5\n",
            "Eh yo eh yo eh yo ouais c’est du rap\n",
            "Anti-BDH (1.3.5, 1.3.5)\n",
            "\n",
            "Rap anti-putes, si tu m’tacles on s’dispute\n",
            "Rap anti-flics, faut qu’je marque on petit but\n",
            "J’oublierai pas les heures de geôles l’école, et toutes ces heures de colle\n",
            "Vas-y rigole, fais pas le mac et lève ta main de mon épaule\n",
            "Les folles elles veulent la drogue accompagnée du Cherry Cola\n",
            "Combien y’a d’frère en tole poto à cause du cher Nicolas ?\n",
            "Ola, c’est un braquage au mic’ mec mec\n",
            "Ça boit la vodka sec calé, freestyle pét’ au bec\n",
            "Impecc’ demain c’est vendredi faut qu’j’touche ma paye\n",
            "J’rentre chez moi il est une heure j’vais encore faire un son qui paye\n",
            "Assez parlé des femmes “elles te veulent pas” m’a dit ma mère\n",
            "J’te jure la vie d’ta mère chez moi c’est made in la merde\n",
            "Ton pote était trop speed j'étais obligé d’le calmer\n",
            "J’ai trop vu Blow, Scarface pour ça qu’j’aime pas les camés\n",
            "Au tieks ça vend la beuh venez j’rabats les clients\n",
            "Quoi qu’est-c’qu’il y a ? Ils m’contrôlent j’les piste en riant\n",
            "You might also like\n",
            "Il faut qu’je gratte il m’faut du liquide faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tire\n",
            "Il faut qu’je gratte il m’faut du liquide\n",
            "Faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tire\n",
            "\n",
            "J’fais ça bien, réfléchis si ça craint\n",
            "Pour moi les sous c’est sacré genre comme Saiah et sa crème\n",
            "Et j’pense à Gil-lou comme la vie c’est nul\n",
            "L’absence de ta mère quand tu es en cellule\n",
            "J’fais des rimes de fou, de zgeg, et ça t’étonne\n",
            "Mon pote reste à l’affût l’soir, quand ça bétonne\n",
            "J’veux pas courir derrière les femmes toi même tu sais j’aime plus l’sport\n",
            "Si t’es en chien qu’tu vois un stunt Monseigneur, le U s’tord\n",
            "J’ai fait plein d’sons pour ce CD mais j’en sortirai qu’un peu\n",
            "Jul c’est la patate à consommer avec un joint d’beuh\n",
            "C’est pas l’maquillage qui t’rend belle en deux mots j’t’emballe\n",
            "Un peu de Clan Campbell j’te ken et j’te remballe\n",
            "Et quand tu es en bas\n",
            "Cesse de faire le Rambo\n",
            "Et ouais c’est fini maintenant c’est la voiture qui t’rend beau\n",
            "C’est toi qui l’as volé donc maintenant t’y vas, tu rends tout\n",
            "Y’a l’feu dans la défense j’calcule pas moi j’tire en touche\n",
            "Il faut qu’je gratte il m’faut du liquide faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tire\n",
            "Il faut qu’je gratte il m’faut du liquide faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tire\n",
            "Il faut qu’je gratte il m’faut du liquide faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tire\n",
            "Il faut qu’je gratte il m’faut du liquide faut qu’ça claque dans ma tête\n",
            "J’me dis faut faire des sous et mettre bien la daronne\n",
            "1.3.5 City, ça piste le Carrefour City\n",
            "Tu fais l’mec tu achètes des Kalash’ porte tes couilles allez vas-y, tireEmbed\n"
          ]
        }
      ],
      "source": [
        "print(cleaned_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a corpus of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "vrbVcj8bWsbp"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for i in range(len(cleaned_data)):\n",
        "    lines = cleaned_data[i].split(\"\\n\")\n",
        "    for line in lines:\n",
        "        line = line.lower()\n",
        "        line_words = [word for word in line.split(' ') if word.strip() != '']\n",
        "        line_words.append(' \\n ')\n",
        "        corpus = corpus + line_words\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "149330"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' \\n ',\n",
              " '1.3.5',\n",
              " ' \\n ',\n",
              " '1.3.5',\n",
              " ' \\n ',\n",
              " 'eh',\n",
              " 'yo',\n",
              " 'eh',\n",
              " 'yo',\n",
              " 'eh',\n",
              " 'yo',\n",
              " 'ouais',\n",
              " 'c’est',\n",
              " 'du',\n",
              " 'rap',\n",
              " ' \\n ',\n",
              " 'anti-bdh',\n",
              " '(1.3.5,',\n",
              " '1.3.5)',\n",
              " ' \\n ']"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "words = set(corpus)\n",
        "nb_words = len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to create the predictors/target from the corpus, to do so we use a sliding window of 15 words, and we predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequence_length = 15\n",
        "step = 2\n",
        "prev_words = []\n",
        "next_words = []\n",
        "sequence = []\n",
        "for i in range(0, len(corpus) - sequence_length, step):\n",
        "    prev_words.append(corpus[i: i + sequence_length ])\n",
        "    next_words.append(corpus[i + sequence_length ])\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74658"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(prev_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xIBoLsbgsR"
      },
      "source": [
        "# Now we are going to use a LSTM architecture that is going to be trained from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "-W23y_i2bgsS",
        "outputId": "ddcd3840-a0ff-4829-f9ac-c9b560d23538"
      },
      "outputs": [],
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "import numpy as np\n",
        "import ker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set of words with index as value\n",
        "word_index = dict((c, i) for i, c in enumerate(words) )\n",
        "# set of words with index as key\n",
        "index_word = dict((i, c) for i, c in enumerate(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty4TWfxObgsU"
      },
      "source": [
        "Setting up a generator to feed the model with data and have no memory issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to generate data from our data set in order to feed our model\n",
        "def generator(prev_word_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, sequence_length), dtype=np.int32)\n",
        "        y = np.zeros((batch_size), dtype=np.int32)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(prev_word_list[index % len(prev_word_list)]):\n",
        "                x[i, t] = word_index[w]\n",
        "            y[i] = word_index[next_word_list[index % len(prev_word_list)]]\n",
        "            index = index + 1\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkzT3YocbgsW"
      },
      "source": [
        "# So now we did all the preprocessing of our data and now we will build our model. We will use LSTM model for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definition of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "BkKk6KVibgsW",
        "outputId": "b34a0b98-a479-4c99-dc4c-98fcdf75aeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 100)         1704400   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               117248    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 17044)             2198676   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4020324 (15.34 MB)\n",
            "Trainable params: 4020324 (15.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build the model: a single LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Add Input Embedding Layer\n",
        "model.add(Embedding(input_dim=nb_words, output_dim=100))\n",
        "    \n",
        "# Add Hidden Layer 1 - LSTM Layer\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "# Add Output Layer\n",
        "model.add(Dense(nb_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(prev_words, next_words, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2334/2334 [==============================] - 129s 54ms/step - loss: 6.7947 - accuracy: 0.1170 - val_loss: 6.7257 - val_accuracy: 0.1215\n",
            "Epoch 2/100\n",
            "2334/2334 [==============================] - 126s 54ms/step - loss: 6.0690 - accuracy: 0.1367 - val_loss: 6.6451 - val_accuracy: 0.1412\n",
            "Epoch 3/100\n",
            "2334/2334 [==============================] - 119s 51ms/step - loss: 5.4714 - accuracy: 0.1632 - val_loss: 6.6577 - val_accuracy: 0.1512\n",
            "Epoch 4/100\n",
            "2334/2334 [==============================] - 118s 51ms/step - loss: 4.9042 - accuracy: 0.1925 - val_loss: 6.6910 - val_accuracy: 0.1637\n",
            "Epoch 5/100\n",
            "2334/2334 [==============================] - 142s 61ms/step - loss: 4.3429 - accuracy: 0.2324 - val_loss: 6.9247 - val_accuracy: 0.1700\n",
            "Epoch 6/100\n",
            "2334/2334 [==============================] - 141s 60ms/step - loss: 3.7981 - accuracy: 0.2884 - val_loss: 6.9137 - val_accuracy: 0.1806\n",
            "Epoch 7/100\n",
            "2334/2334 [==============================] - 138s 59ms/step - loss: 3.2975 - accuracy: 0.3582 - val_loss: 7.1615 - val_accuracy: 0.1774\n",
            "Epoch 8/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 2.8622 - accuracy: 0.4299 - val_loss: 7.1291 - val_accuracy: 0.1905\n",
            "Epoch 9/100\n",
            "2334/2334 [==============================] - 149s 64ms/step - loss: 2.5000 - accuracy: 0.4927 - val_loss: 7.3243 - val_accuracy: 0.1959\n",
            "Epoch 10/100\n",
            "2334/2334 [==============================] - 144s 62ms/step - loss: 2.1950 - accuracy: 0.5480 - val_loss: 7.2541 - val_accuracy: 0.2030\n",
            "Epoch 11/100\n",
            "2334/2334 [==============================] - 140s 60ms/step - loss: 1.8987 - accuracy: 0.6042 - val_loss: 7.5983 - val_accuracy: 0.1901\n",
            "Epoch 12/100\n",
            "2334/2334 [==============================] - 145s 62ms/step - loss: 1.6452 - accuracy: 0.6536 - val_loss: 7.6423 - val_accuracy: 0.2045\n",
            "Epoch 13/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 1.4715 - accuracy: 0.6857 - val_loss: 7.7153 - val_accuracy: 0.2006\n",
            "Epoch 14/100\n",
            "2334/2334 [==============================] - 147s 63ms/step - loss: 1.3044 - accuracy: 0.7161 - val_loss: 7.6312 - val_accuracy: 0.2039\n",
            "Epoch 15/100\n",
            "2334/2334 [==============================] - 141s 60ms/step - loss: 1.1593 - accuracy: 0.7456 - val_loss: 8.0009 - val_accuracy: 0.2046\n",
            "Epoch 16/100\n",
            "2334/2334 [==============================] - 134s 57ms/step - loss: 1.0109 - accuracy: 0.7769 - val_loss: 8.0188 - val_accuracy: 0.2122\n",
            "Epoch 17/100\n",
            "2334/2334 [==============================] - 146s 63ms/step - loss: 0.9350 - accuracy: 0.7891 - val_loss: 8.0686 - val_accuracy: 0.2096\n",
            "Epoch 18/100\n",
            "2334/2334 [==============================] - 164s 70ms/step - loss: 0.8591 - accuracy: 0.8046 - val_loss: 7.9858 - val_accuracy: 0.2103\n",
            "Epoch 19/100\n",
            "2334/2334 [==============================] - 150s 64ms/step - loss: 0.7854 - accuracy: 0.8212 - val_loss: 8.2637 - val_accuracy: 0.2158\n",
            "Epoch 20/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.7100 - accuracy: 0.8357 - val_loss: 8.3608 - val_accuracy: 0.2202\n",
            "Epoch 21/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 0.6724 - accuracy: 0.8423 - val_loss: 8.3561 - val_accuracy: 0.2163\n",
            "Epoch 22/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 0.6425 - accuracy: 0.8493 - val_loss: 8.2923 - val_accuracy: 0.2157\n",
            "Epoch 23/100\n",
            "2334/2334 [==============================] - 155s 67ms/step - loss: 0.5982 - accuracy: 0.8584 - val_loss: 8.4755 - val_accuracy: 0.2160\n",
            "Epoch 24/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 0.5509 - accuracy: 0.8685 - val_loss: 8.5145 - val_accuracy: 0.2247\n",
            "Epoch 25/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.5369 - accuracy: 0.8720 - val_loss: 8.5460 - val_accuracy: 0.2213\n",
            "Epoch 26/100\n",
            "2334/2334 [==============================] - 155s 66ms/step - loss: 0.5219 - accuracy: 0.8734 - val_loss: 8.4693 - val_accuracy: 0.2208\n",
            "Epoch 27/100\n",
            "2334/2334 [==============================] - 150s 64ms/step - loss: 0.5010 - accuracy: 0.8776 - val_loss: 8.6423 - val_accuracy: 0.2240\n",
            "Epoch 28/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.4681 - accuracy: 0.8854 - val_loss: 8.6696 - val_accuracy: 0.2299\n",
            "Epoch 29/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.4576 - accuracy: 0.8881 - val_loss: 8.6352 - val_accuracy: 0.2303\n",
            "Epoch 30/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.4528 - accuracy: 0.8890 - val_loss: 8.5453 - val_accuracy: 0.2244\n",
            "Epoch 31/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.4362 - accuracy: 0.8915 - val_loss: 8.7443 - val_accuracy: 0.2301\n",
            "Epoch 32/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.4193 - accuracy: 0.8948 - val_loss: 8.7929 - val_accuracy: 0.2303\n",
            "Epoch 33/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.4329 - accuracy: 0.8919 - val_loss: 8.6993 - val_accuracy: 0.2313\n",
            "Epoch 34/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.4136 - accuracy: 0.8958 - val_loss: 8.5801 - val_accuracy: 0.2281\n",
            "Epoch 35/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.3994 - accuracy: 0.8984 - val_loss: 8.7731 - val_accuracy: 0.2368\n",
            "Epoch 36/100\n",
            "2334/2334 [==============================] - 137s 59ms/step - loss: 0.3754 - accuracy: 0.9058 - val_loss: 8.8216 - val_accuracy: 0.2378\n",
            "Epoch 37/100\n",
            "2334/2334 [==============================] - 138s 59ms/step - loss: 0.3629 - accuracy: 0.9083 - val_loss: 8.8152 - val_accuracy: 0.2394\n",
            "Epoch 38/100\n",
            "2334/2334 [==============================] - 137s 59ms/step - loss: 0.3654 - accuracy: 0.9085 - val_loss: 8.6678 - val_accuracy: 0.2365\n",
            "Epoch 39/100\n",
            "2334/2334 [==============================] - 139s 59ms/step - loss: 0.3624 - accuracy: 0.9083 - val_loss: 8.8289 - val_accuracy: 0.2424\n",
            "Epoch 40/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.3570 - accuracy: 0.9096 - val_loss: 8.8667 - val_accuracy: 0.2462\n",
            "Epoch 41/100\n",
            "2334/2334 [==============================] - 136s 58ms/step - loss: 0.3592 - accuracy: 0.9079 - val_loss: 8.8045 - val_accuracy: 0.2435\n",
            "Epoch 42/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.3573 - accuracy: 0.9088 - val_loss: 8.6698 - val_accuracy: 0.2463\n",
            "Epoch 43/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.3444 - accuracy: 0.9118 - val_loss: 8.8065 - val_accuracy: 0.2481\n",
            "Epoch 44/100\n",
            "2334/2334 [==============================] - 135s 58ms/step - loss: 0.3339 - accuracy: 0.9140 - val_loss: 8.8857 - val_accuracy: 0.2544\n",
            "Epoch 45/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 0.3205 - accuracy: 0.9185 - val_loss: 8.8304 - val_accuracy: 0.2511\n",
            "Epoch 46/100\n",
            "2334/2334 [==============================] - 155s 67ms/step - loss: 0.3180 - accuracy: 0.9189 - val_loss: 8.7619 - val_accuracy: 0.2557\n",
            "Epoch 47/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.2992 - accuracy: 0.9243 - val_loss: 8.8738 - val_accuracy: 0.2533\n",
            "Epoch 48/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.2888 - accuracy: 0.9267 - val_loss: 8.9552 - val_accuracy: 0.2546\n",
            "Epoch 49/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 0.2979 - accuracy: 0.9239 - val_loss: 8.8498 - val_accuracy: 0.2564\n",
            "Epoch 50/100\n",
            "2334/2334 [==============================] - 155s 66ms/step - loss: 0.3003 - accuracy: 0.9239 - val_loss: 8.7841 - val_accuracy: 0.2608\n",
            "Epoch 51/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 0.2912 - accuracy: 0.9245 - val_loss: 8.8090 - val_accuracy: 0.2615\n",
            "Epoch 52/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.2720 - accuracy: 0.9303 - val_loss: 9.0171 - val_accuracy: 0.2592\n",
            "Epoch 53/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 0.2687 - accuracy: 0.9306 - val_loss: 8.9033 - val_accuracy: 0.2610\n",
            "Epoch 54/100\n",
            "2334/2334 [==============================] - 155s 66ms/step - loss: 0.2702 - accuracy: 0.9303 - val_loss: 8.8102 - val_accuracy: 0.2626\n",
            "Epoch 55/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.2624 - accuracy: 0.9323 - val_loss: 8.8411 - val_accuracy: 0.2656\n",
            "Epoch 56/100\n",
            "2334/2334 [==============================] - 155s 66ms/step - loss: 0.2513 - accuracy: 0.9351 - val_loss: 9.0478 - val_accuracy: 0.2632\n",
            "Epoch 57/100\n",
            "2334/2334 [==============================] - 155s 66ms/step - loss: 0.2506 - accuracy: 0.9350 - val_loss: 8.9985 - val_accuracy: 0.2629\n",
            "Epoch 58/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.2481 - accuracy: 0.9365 - val_loss: 8.8675 - val_accuracy: 0.2722\n",
            "Epoch 59/100\n",
            "2334/2334 [==============================] - 163s 70ms/step - loss: 0.2584 - accuracy: 0.9317 - val_loss: 8.8983 - val_accuracy: 0.2707\n",
            "Epoch 60/100\n",
            "2334/2334 [==============================] - 158s 68ms/step - loss: 0.2381 - accuracy: 0.9389 - val_loss: 9.0535 - val_accuracy: 0.2697\n",
            "Epoch 61/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.2348 - accuracy: 0.9387 - val_loss: 8.9618 - val_accuracy: 0.2734\n",
            "Epoch 62/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.2352 - accuracy: 0.9380 - val_loss: 8.9121 - val_accuracy: 0.2743\n",
            "Epoch 63/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.2311 - accuracy: 0.9392 - val_loss: 8.9002 - val_accuracy: 0.2762\n",
            "Epoch 64/100\n",
            "2334/2334 [==============================] - 158s 68ms/step - loss: 0.2162 - accuracy: 0.9438 - val_loss: 9.0563 - val_accuracy: 0.2736\n",
            "Epoch 65/100\n",
            "2334/2334 [==============================] - 160s 68ms/step - loss: 0.2127 - accuracy: 0.9446 - val_loss: 9.0432 - val_accuracy: 0.2754\n",
            "Epoch 66/100\n",
            "2334/2334 [==============================] - 158s 68ms/step - loss: 0.2082 - accuracy: 0.9462 - val_loss: 8.9712 - val_accuracy: 0.2812\n",
            "Epoch 67/100\n",
            "2334/2334 [==============================] - 158s 68ms/step - loss: 0.1983 - accuracy: 0.9482 - val_loss: 9.0153 - val_accuracy: 0.2841\n",
            "Epoch 68/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.1917 - accuracy: 0.9498 - val_loss: 9.1714 - val_accuracy: 0.2805\n",
            "Epoch 69/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.1862 - accuracy: 0.9515 - val_loss: 9.0857 - val_accuracy: 0.2816\n",
            "Epoch 70/100\n",
            "2334/2334 [==============================] - 158s 68ms/step - loss: 0.1835 - accuracy: 0.9522 - val_loss: 8.9952 - val_accuracy: 0.2833\n",
            "Epoch 71/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 0.1759 - accuracy: 0.9538 - val_loss: 9.0277 - val_accuracy: 0.2853\n",
            "Epoch 72/100\n",
            "2334/2334 [==============================] - 154s 66ms/step - loss: 0.1703 - accuracy: 0.9553 - val_loss: 9.2707 - val_accuracy: 0.2808\n",
            "Epoch 73/100\n",
            "2334/2334 [==============================] - 153s 66ms/step - loss: 0.1626 - accuracy: 0.9573 - val_loss: 9.1884 - val_accuracy: 0.2835\n",
            "Epoch 74/100\n",
            "2334/2334 [==============================] - 156s 67ms/step - loss: 0.1585 - accuracy: 0.9585 - val_loss: 9.1033 - val_accuracy: 0.2885\n",
            "Epoch 75/100\n",
            "2334/2334 [==============================] - 162s 69ms/step - loss: 0.1527 - accuracy: 0.9609 - val_loss: 9.1555 - val_accuracy: 0.2861\n",
            "Epoch 76/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.1485 - accuracy: 0.9616 - val_loss: 9.3267 - val_accuracy: 0.2848\n",
            "Epoch 77/100\n",
            "2334/2334 [==============================] - 157s 67ms/step - loss: 0.1426 - accuracy: 0.9630 - val_loss: 9.2845 - val_accuracy: 0.2867\n",
            "Epoch 78/100\n",
            "2334/2334 [==============================] - 159s 68ms/step - loss: 0.1379 - accuracy: 0.9638 - val_loss: 9.2132 - val_accuracy: 0.2883\n",
            "Epoch 79/100\n",
            "2334/2334 [==============================] - 160s 69ms/step - loss: 0.1339 - accuracy: 0.9658 - val_loss: 9.1971 - val_accuracy: 0.2877\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x16eb9646910>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "model.fit(generator(X_train, y_train, BATCH_SIZE), steps_per_epoch = int(len(prev_words)/BATCH_SIZE) + 1, epochs=100, verbose=1, callbacks=[early_stopping],validation_data=generator(X_test, y_test, BATCH_SIZE), validation_steps=int(len(X_test)/BATCH_SIZE) + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We save it in case we want only to reuse it as it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"my_model.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "#model = keras.models.load_model(\"my_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         1704400   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 17044)             2198676   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4020324 (15.34 MB)\n",
            "Trainable params: 4020324 (15.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHCmG84vbgsY"
      },
      "source": [
        "# Now that it's trained we can use it to generate lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firslty we are just taking the best next word from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "hmIfcewnbgsY"
      },
      "outputs": [],
      "source": [
        "source = \"je t'aime a la folie\"\n",
        "source = source.split(' ')\n",
        "n_token = 100\n",
        "lyrics = source.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['je', \"t'aime\", 'a', 'la', 'folie']"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = source.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "je t'aime a la folie  \n",
            "  dans l’dos mon rap poto te dire qu'il te \"tu poussette j'porte pas l'temps, le temps  \n",
            "  c'est pas facile, tu lui as tranquille j'en connais  \n",
            "   \n",
            "  et j'te vois pas j’observe  \n",
            "  j'fume des petits avant parler de malade  \n",
            "  il a grandi sur la rue me crois peu, s'énerve,  \n",
            "  elle voir dans la suis dans le quartier  \n",
            "  et on double on c’est la grosse tête  \n",
            "  ça parle de danse, ouais  \n",
            "  demande à azzedine on nous chez sur  \n",
            "   \n",
            "  j’fais pas mon temps là you might also like  \n",
            "  aski' parait j'ai\n"
          ]
        }
      ],
      "source": [
        "temperature = 1  # Adjust the temperature value for different levels of randomness\n",
        "\n",
        "for i in range(n_token):\n",
        "    encoded = []\n",
        "    for word in input_text:\n",
        "        encoded.append(word_index[word])\n",
        "    encoded = np.array(encoded)\n",
        "    encoded = encoded.reshape(1, len(encoded))\n",
        "    y_pred = model.predict(encoded, verbose=0)\n",
        "    y_pred = y_pred / temperature  \n",
        "    y_pred = y_pred/np.sum(y_pred)\n",
        "    # Apply temperature to adjust the randomness of predictions\n",
        "    y_pred = np.random.choice(range(nb_words), size=1, p=y_pred[0])[0]\n",
        "    input_text.append(index_word[y_pred])\n",
        "    if len(input_text) > sequence_length:\n",
        "        input_text = input_text[1:]\n",
        "    lyrics.append(index_word[y_pred])\n",
        "print(' '.join(lyrics))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
